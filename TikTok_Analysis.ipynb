{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "# data = [json.loads(line) for line in open(r'C:\\Users\\Mhaiskao\\Desktop\\Assignments\\MSc Project\\tiktok.json', 'r',encoding=\"utf8\")]\n",
    "data = [json.loads(line) for line in open(r'C:\\Users\\Mhaiskao\\Desktop\\Assignments\\MSc Project\\scraper\\tiktok.json', 'r',encoding=\"utf8\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(data[84594])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################IMp###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "id_list=[]\n",
    "text_list=[]\n",
    "Music_id_list=[]\n",
    "Music_name_list=[]\n",
    "Author_id_list=[]\n",
    "Created_time=[]\n",
    "verified_list=[]\n",
    "\n",
    "sharecount_list=[]\n",
    "digcount_list=[]\n",
    "commentcount_list=[]\n",
    "scrape_time_list=[]\n",
    "weekday_list=[]\n",
    "\n",
    "playcount_list=[]\n",
    "final_comment_count=[]\n",
    "final_share_count=[]\n",
    "final_digg_count=[]\n",
    "final_play_count=[]\n",
    "bin_time_list=[]\n",
    "challenge_name_list=[]\n",
    "challenge_id_list=[]\n",
    "\n",
    "for i in range(0,len(data)):\n",
    "    id_list.append(data[i]['tiktokData'][0]['itemInfos']['id'])\n",
    "    text_list.append(data[i]['tiktokData'][0]['itemInfos']['text'].lower())\n",
    "    Music_id_list.append(data[i]['tiktokData'][0]['musicInfos']['musicId'])\n",
    "    Music_name_list.append(data[i]['tiktokData'][0]['musicInfos']['musicName'])\n",
    "    Author_id_list.append(data[i]['tiktokData'][0]['itemInfos']['authorId'])\n",
    "    created_date=parser.isoparse(data[i]['createdAt']['$date'])\n",
    "    Created_time.append(created_date.strftime(\"%x\"))\n",
    "    verified_list.append(data[i]['tiktokData'][0]['authorInfos']['verified'])\n",
    "    \n",
    "    #Save challenges Name and Challenge Id for every video\n",
    "    \n",
    "    challenge_name=[]\n",
    "    challenge_id=[]\n",
    "    \n",
    "    #Check if no challenges are present\n",
    "    \n",
    "    if len(data[i]['tiktokData'][0]['challengeInfoList']) == 0:\n",
    "        challenge_id.append('Empty')\n",
    "        challenge_name.append('Empty')\n",
    "    else:\n",
    "        for j in range(0,len(data[i]['tiktokData'][0]['challengeInfoList'])):\n",
    "            challenge_id.append(data[i]['tiktokData'][0]['challengeInfoList'][j]['challengeId'])\n",
    "            challenge_name.append(data[i]['tiktokData'][0]['challengeInfoList'][j]['challengeName'])\n",
    "    challenge_id_list.append(challenge_id)\n",
    "    challenge_name_list.append(challenge_name)\n",
    "    \n",
    "    #Get Share, Comment and Digg Count \n",
    "    \n",
    "    sharecount=[]\n",
    "    digcount=[]\n",
    "    commentcount=[]\n",
    "    scrape_time=[]\n",
    "    playcount=[]\n",
    "    bin_time=[]\n",
    "    weekday=[]\n",
    "    for j in range(0,len(data[i]['tiktokData'])):   \n",
    "        date=parser.isoparse(data[i]['tiktokData'][j]['scrapedAt']['$date'])\n",
    "        digcount.append(data[i]['tiktokData'][j]['itemInfos']['diggCount'])\n",
    "        sharecount.append(data[i]['tiktokData'][j]['itemInfos']['shareCount'])\n",
    "        commentcount.append(data[i]['tiktokData'][j]['itemInfos']['commentCount'])\n",
    "        scrape_time.append(date.strftime(\"%x %H\"))\n",
    "        if date.hour in range(0,6):\n",
    "            bin_time.append(\"{} , {}\".format(date.strftime(\"%x %w\"),'Part 1'))\n",
    "            weekday.append(date.strftime(\"%w\"))\n",
    "#             part.append('Part 1')\n",
    "        elif date.hour in range(7,12):\n",
    "            bin_time.append(\"{} , {}\".format(date.strftime(\"%x %w\"),'Part 2'))\n",
    "            weekday.append(date.strftime(\"%w\"))\n",
    "#             part.append('Part 2')\n",
    "        elif date.hour in range(13,18):\n",
    "            bin_time.append(\"{} , {}\".format(date.strftime(\"%x %w\"),'Part 3'))\n",
    "            weekday.append(date.strftime(\"%w\"))\n",
    "#             part.append('Part 3')\n",
    "        else:\n",
    "            bin_time.append(\"{} , {}\".format(date.strftime(\"%x %w\"),'Part 4'))\n",
    "            weekday.append(date.strftime(\"%w\"))\n",
    "#             part.append('Part 4')\n",
    "        try:\n",
    "            playcount.append(data[i]['tiktokData'][j]['itemInfos']['playCount'])\n",
    "        except KeyError:\n",
    "            playcount.append(0)\n",
    "    weekday_list.append(weekday)\n",
    "    bin_time_list.append(bin_time)        \n",
    "    sharecount_list.append(sharecount)\n",
    "    digcount_list.append(digcount)\n",
    "    commentcount_list.append(commentcount)\n",
    "    final_comment_count.append(commentcount[-1])\n",
    "    scrape_time_list.append(scrape_time)\n",
    "#     part_list.append(part)\n",
    "    weekday_list.append(weekday)\n",
    "    playcount_list.append(playcount) \n",
    "    final_share_count.append(sharecount[-1])\n",
    "    final_digg_count.append(digcount[-1])\n",
    "    final_play_count.append(playcount[-1])\n",
    "    \n",
    "df_final=pd.DataFrame(list(zip(id_list,text_list,Music_id_list,Music_name_list,Author_id_list,Created_time,verified_list,challenge_id_list,\n",
    "                               challenge_name_list,sharecount_list,final_share_count,digcount_list,final_digg_count,commentcount_list,\n",
    "                               final_comment_count,scrape_time_list,weekday_list,bin_time_list,playcount_list,final_play_count)),\n",
    "                       columns=['ID','Text','Music Id','Music Name','Author ID','Created Time','Verified List','challenge_list',\n",
    "                                'challenge_list_Name','Sharecount List','Final Share Count','Diggcount List','Final Digg Count',\n",
    "                                'Commentcount List','Final Comment Count','Scrape_time List','weekday_list','Bin Time','Playcount List','Final Play Count'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get author id for specific commencial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "def hashtag(sub):\n",
    "# creating and passsing series to new column \n",
    "    df_sub_string=df_final[df_final[\"Text\"].str.contains(sub,regex=True)]\n",
    "    df_sub_string.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    return(df_sub_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import itertools\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "arima_df=pd.DataFrame()\n",
    "mean_comment=pd.DataFrame()\n",
    "mean_comment['Time']=arima_df['time']=df_final['Bin Time'][0]\n",
    "mean_comment['Weekday']=df_final['weekday_list'][0]\n",
    "mean_comment['likes']=df_final['Diggcount List'][0]\n",
    "mean_comment['Per Change']=mean_comment['likes'].diff()\n",
    "mean_comment=mean_comment.groupby(['Time'])['Per Change'].sum()\n",
    "\n",
    "#Convert to DataFrame\n",
    "frame = { 'Time Data': mean_comment.index, 'Likes Value': mean_comment.values } \n",
    "result = pd.DataFrame(frame) \n",
    "weekday=[]\n",
    "for i in range(0,len(result)):\n",
    "    string=result['Time Data'][i]\n",
    "    string1=string.split()\n",
    "    weekday.append(int(string1[1]))\n",
    "result['Weekday']=weekday\n",
    "\n",
    "TrainingSize = int(0.8*result.shape[0])\n",
    "TestSize = result.shape[0] - TrainingSize\n",
    "exog_value=result.iloc[0:TrainingSize,2]\n",
    "\n",
    "p=q=d=range(0,1)\n",
    "pdq=list(itertools.product(p,d,q))\n",
    "seasonal_pdq = [(x[0], x[1], x[2], 4) for x in list(itertools.product(p, d, q))]\n",
    "mean_squared=[]\n",
    "pdq_values=[]\n",
    "aic=[]\n",
    "\n",
    "for param in pdq:\n",
    "    for param2 in seasonal_pdq:\n",
    "        try:\n",
    "            #Define seasonal and normal parameter\n",
    "            my_order = param\n",
    "            my_seasonal_order = param2\n",
    "\n",
    "            #Train the model\n",
    "            model = SARIMAX(result.iloc[0:TrainingSize,1], \n",
    "                            order=my_order, seasonal_order=my_seasonal_order,\n",
    "                            exog=exog_value,simple_differencing=True)\n",
    "#             model = SARIMAX(result.iloc[0:TrainingSize,1], \n",
    "#                             order=my_order, seasonal_order=my_seasonal_order,simple_differencing=True)\n",
    "            #Fit the model\n",
    "            model_fit = model.fit()        \n",
    "\n",
    "            #Forecast for next Test Size\n",
    "            yhat =model_fit.forecast(TestSize,exog=pd.DataFrame(result['Weekday'])[TrainingSize:])\n",
    "\n",
    "            #Calculate mean squared error\n",
    "            mean_squared.append(mean_squared_error(np.ceil(yhat),result.iloc[TrainingSize:,1]))\n",
    "\n",
    "            pdq_values.append((param,param2))\n",
    "            aic.append(model_fit.aic)\n",
    "        except:\n",
    "            print('In except')\n",
    "            continue\n",
    "            \n",
    "mydict=dict(zip(pdq_values,mean_squared))\n",
    "mydict2=dict(zip(pdq_values,aic))\n",
    "\n",
    "Keymax = min(mydict, key= lambda x: mydict[x])\n",
    "print(Keymax)\n",
    "my_order,my_seasonal_order=Keymax\n",
    "\n",
    "#Train model\n",
    "model = SARIMAX(result.iloc[0:TrainingSize,1], \n",
    "                            order=my_order, seasonal_order=my_seasonal_order,\n",
    "                            exog=exog_value)\n",
    "# model = SARIMAX(result.iloc[0:TrainingSize,1], \n",
    "#                             order=my_order, seasonal_order=my_seasonal_order)\n",
    "\n",
    "model_fit = model.fit()\n",
    "yhat =model_fit.forecast(TestSize,exog=pd.DataFrame(result['Weekday'])[TrainingSize:])\n",
    "\n",
    "print(mean_squared_error(np.ceil(yhat),result.iloc[TrainingSize:,1]))\n",
    "print(yhat)\n",
    "print(result.iloc[TrainingSize:,1])\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "value=mean_absolute_percentage_error(result.iloc[TrainingSize:,1],yhat)\n",
    "# mean_comment.plot.bar(figsize=(30,10))\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from datetime import datetime, timedelta\n",
    "import itertools\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "def visualize_arima(output,time,mean_comment):\n",
    "    #save the last date and use stripftime to generate 7 days from last date\n",
    "    date_time_str = time[-1]\n",
    "    Predicted_Value_dates=[]\n",
    "\n",
    "    #check if length of input was 1\n",
    "    if len(mean_comment)==1:\n",
    "        for i in range(1,8):\n",
    "            res = (datetime.strptime(date_time_str, '%m/%d/%y %H') + timedelta(days=i)).strftime('%m/%d/%y %H')\n",
    "            Predicted_Value_dates.append((res,output))   \n",
    "    else:\n",
    "        for i in range(1,8):\n",
    "            res = (datetime.strptime(date_time_str, '%m/%d/%y %H') + timedelta(days=i)).strftime('%m/%d/%y %H')\n",
    "            Predicted_Value_dates.append((res,output[i-1]))\n",
    "\n",
    "    #create data frame to plot the graphs\n",
    "    df1=pd.DataFrame()\n",
    "    df=pd.DataFrame()\n",
    "    df[['Date','Predicted_Value']]=pd.DataFrame(Predicted_Value_dates)\n",
    "\n",
    "    mean_comment_time=[]\n",
    "    for i in range(len(mean_comment)):\n",
    "        mean_comment_time.append((mean_comment.index[i],mean_comment[i]))\n",
    "\n",
    "    df1[['Date','Orignal_Value']]=pd.DataFrame(mean_comment_time)\n",
    "\n",
    "    # Initialize figure with subplots\n",
    "    fig = make_subplots(rows=1, cols=2)\n",
    "\n",
    "\n",
    "    # Add Comment Count Scatter chart\n",
    "    fig.add_trace(go.Scatter(x=df1['Date'], y=df1['Orignal_Value'], name='Orignal Values',\n",
    "                             line = dict(color='red', width=2)),row=1,col=1)\n",
    "\n",
    "    # Add Share Count Scatter chart\n",
    "    fig.add_trace(go.Scatter(x=df['Date'], y=df['Predicted_Value'], name='Predicted Values',\n",
    "                             line = dict(color='blue', width=2)),row=1,col=2)\n",
    "\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "def arima_model(sub_string,index):\n",
    "    parameters=[]\n",
    "    aic=[]\n",
    "    mydict={}\n",
    "    \n",
    "    arima_df=pd.DataFrame()\n",
    "    Time=arima_df['time']=sub_string['Scrape_time List'][index]\n",
    "    arima_df['comment']=sub_string['Commentcount List'][index]\n",
    "    \n",
    "    mean_comment=arima_df.groupby('time')['comment'].mean()\n",
    "    mean_comment=np.floor(mean_comment)\n",
    "\n",
    "    p=q=d=range(0,5)\n",
    "    pdq=list(itertools.product(p,d,q))\n",
    "    \n",
    "    for param in pdq:\n",
    "        # fit model\n",
    "        try:\n",
    "            model = ARIMA(mean_comment, order=param)\n",
    "            model_fit = model.fit(disp=0)\n",
    "            output=model_fit.forecast(steps=2)[0]\n",
    "            parameters.append(param)\n",
    "            aic.append(model_fit.aic)\n",
    "            \n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    mydict=dict(zip(parameters,aic))\n",
    "    if len(mydict)==0:\n",
    "\n",
    "        return visualize_arima(mean_comment[0], Time, mean_commen)\n",
    "    \n",
    "    Keymax = min(mydict, key= lambda x: mydict[x])\n",
    "    model = ARIMA(mean_comment, order=Keymax)\n",
    "    model_fit = model.fit(disp=0)\n",
    "    output=model_fit.forecast(steps=7)[0]\n",
    "    \n",
    "    return visualize_arima(output,Time,mean_comment)\n",
    "##############################################################\n",
    "sub_string=hashtag('lol')\n",
    "fig=arima_model(sub_string,0)\n",
    "fig.show()\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.write_html(fig, file='arima_visualization.html', auto_open=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential Influencers:  value= [(sharecount + diggcount + commentcount)/playcount] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Calculate_Engagement_rate(df_sub_string,authorid):\n",
    "    rslt_df = df_sub_string.loc[df_sub_string['Author ID'] == authorid]\n",
    "    rslt_df.reset_index(inplace=True,drop=True)\n",
    "    rslt_df.sort_values(\"Created Time\", axis = 0, ascending = False, inplace = True) \n",
    "    \n",
    "    #Calculate enagament rate using formular ER=[(sharecount + diggcount + commentcount)/playcount] * 100\n",
    "    Numerator=rslt_df['Final Share Count'] + rslt_df['Final Comment Count'] + rslt_df['Final Digg Count']\n",
    "    Numerator_value=sum(np.array(Numerator))\n",
    "    Denominator=rslt_df['Final Play Count']\n",
    "    Denominator_value=sum(np.array(Denominator))\n",
    "    Engagement_rate= (Numerator_value/Denominator_value)*100\n",
    "    Engagement_rate\n",
    "    return Engagement_rate\n",
    "\n",
    "def potential_influencers(hashtag_string):\n",
    "    Engagement_rate_list=[]\n",
    "    Engagement_rate_list_complete=[]\n",
    "    Author_ID_list=[]\n",
    "    \n",
    "    df_sub_string=hashtag(hashtag_string.lower())\n",
    "    \n",
    "    #Influencers with maximum videos\n",
    "    df_top_influencers=pd.DataFrame()\n",
    "    df_top_influencers['Author ID']=df_sub_string.groupby(\"Author ID\",sort=False)[\"ID\"].count().sort_values(ascending=False)\n",
    "    \n",
    "    for i in range(0,len(df_top_influencers)):\n",
    "        #save Engagement rate for each author\n",
    "        Engagement_rate_list.append(Calculate_Engagement_rate(df_sub_string,df_top_influencers['Author ID'].index[i]))\n",
    "        Engagement_rate_list_complete.append(Calculate_Engagement_rate(df_final,df_top_influencers['Author ID'].index[i]))\n",
    "        #save author id\n",
    "        Author_ID_list.append(df_top_influencers['Author ID'].index[i])\n",
    "    return Engagement_rate_list,Author_ID_list,Engagement_rate_list_complete\n",
    "\n",
    "ER,Author_ID,ER_complete=potential_influencers('puma')\n",
    "df_influencers=pd.DataFrame()\n",
    "df_influencers[['ER','Author_ID']]=pd.DataFrame(list(zip(ER,Author_ID)))\n",
    "df_influencers.sort_values('ER', inplace=True, ascending=False)\n",
    "\n",
    "################\n",
    "df_influencers_complete=pd.DataFrame()\n",
    "df_influencers_complete[['ER','Author_ID']]=pd.DataFrame(list(zip(ER_complete,Author_ID)))\n",
    "df_influencers_complete.sort_values('ER', inplace=True, ascending=False)\n",
    "df_influencers_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_influencers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['Text'].loc[df_final['Author ID'] == '6613398665766305798']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data[84594]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_text=df_final[['Music Id','Author ID','challenge_list_Name','Verified List']]\n",
    "\n",
    "# df_text=df_text.rename(columns = {'Author ID':'source'})\n",
    "# df_text=df_text.rename(columns = {'challenge_list_Name':'target'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def remove_zero_challenges(df_final):\n",
    "    #Remove rows having Zero challenges \n",
    "    df_text=df_final[['Music Id','Author ID','challenge_list_Name','Verified List']]\n",
    "    drop_index=[]\n",
    "    for i in range(0,len(df_text)):\n",
    "        if df_text['challenge_list_Name'][i]==['Empty']:\n",
    "            drop_index.append(i)\n",
    "    df_text.drop(df_text.index[drop_index],inplace=True)\n",
    "    df_text.reset_index(drop=True, inplace=True)\n",
    "    return df_text\n",
    "\n",
    "# df_text=remove_zero_challenges(df_text)\n",
    "# df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def challenges_for_verified_users(df_text):\n",
    "    #Challenges associated with verifed users\n",
    "    listauthor=[]\n",
    "    author=[]\n",
    "    listauthor=df_text.index[df_text['Verified List'] == True].tolist()\n",
    "    for i in listauthor:\n",
    "        author.append([df_text['Author ID'][i],df_text['Music Id'][i],df_text['challenge_list_Name'][i]])\n",
    "    df_verified_user_challenges=pd.DataFrame()\n",
    "    df_verified_user_challenges[['Author ID','Music Id','challenge_list_Name']]=pd.DataFrame(author)\n",
    "    return df_verified_user_challenges\n",
    "\n",
    "df_verified_user_challenges=challenges_for_verified_users(remove_zero_challenges(df_final))\n",
    "df_verified_user_challenges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create list having format author : challenge1 for force directed graph  \n",
    "\n",
    "def create_df_graph(df_text):\n",
    "    append_list=[]\n",
    "    for i in range(0,len(df_text['Author ID'])): \n",
    "        for j in df_text['challenge_list_Name'][i]:       \n",
    "             append_list.append([df_text['Music Id'][i],df_text['Author ID'][i],j,1])\n",
    "    cols = ['Music ID','Author ID','challenge_list_Name','weight']\n",
    "\n",
    "    df_graph = pd.DataFrame(append_list,columns=cols)  \n",
    "    return df_graph\n",
    "\n",
    "def unique_values(dataframe,columnname):\n",
    "    dataframereturn=pd.DataFrame()\n",
    "    dataframereturn=dataframe[columnname].value_counts().rename_axis('unique_values').reset_index(name='counts')\n",
    "    return dataframereturn\n",
    "\n",
    "#Unique values for Author ID\n",
    "df_bar_author_id=unique_values(df_final,'Author ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def visualize_CMD(df_final,tiktokid):\n",
    "    index=df_final.index[df_final['ID'] == tiktokid].tolist()\n",
    "    comment_count=df_final['Commentcount List'][index[0]]\n",
    "    share_count=df_final['Sharecount List'][index[0]]\n",
    "    play_count=df_final['Playcount List'][index[0]]\n",
    "    digg_count=df_final['Diggcount List'][index[0]]\n",
    "    scrape_time=df_final['Scrape_time List'][index[0]]\n",
    "\n",
    "    # Initialize figure with subplots\n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=2,\n",
    "        column_widths=[0.9, 0.9],\n",
    "        row_heights=[0.5, 0.2,0.5],\n",
    "        specs=[[{\"type\": \"Scatter\"}, {\"type\": \"Scatter\"}],\n",
    "               [None , None ],\n",
    "               [{\"type\": \"Scatter\"}, {\"type\": \"Scatter\"}]])\n",
    "\n",
    "\n",
    "    # Add Comment Count Scatter chart\n",
    "    fig.add_trace(go.Scatter(x=scrape_time, y=comment_count, name='Comment Count',\n",
    "                             line = dict(color='red', width=2)),row=1,col=1)\n",
    "\n",
    "    # Add Share Count Scatter chart\n",
    "    fig.add_trace(go.Scatter(x=scrape_time, y=share_count, name='Share Count',\n",
    "                             line = dict(color='blue', width=2)),row=1,col=2)\n",
    "\n",
    "    # Add Digg Count Scatter chart\n",
    "    fig.add_trace(go.Scatter(x=scrape_time, y=digg_count, name='Digg Count',\n",
    "                             line = dict(color='green', width=2)),row=3,col=1)\n",
    "\n",
    "    # Add Playcount Count Scatter chart\n",
    "    fig.add_trace(go.Scatter(x=scrape_time, y=play_count, name='Play Count',\n",
    "                             line = dict(color='black', width=2)),row=3,col=2)\n",
    "\n",
    "    return fig\n",
    "\n",
    "fig=visualize_CMD(df_final,'6789793077612547333')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Plot bar grpah for top 20 CHALLENGES\n",
    "\n",
    "import plotly.express as px\n",
    "def visualize_top20_challenge(df_graph):\n",
    "    df_bar_challenge=unique_values(df_graph,'challenge_list_Name')\n",
    "    fig = px.bar(df_bar_challenge[0:20], y='counts', x='unique_values', text='counts')\n",
    "    fig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\n",
    "    return fig\n",
    "fig=visualize_top20_challenge(create_df_graph(remove_zero_challenges(df_final)))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Plot bar graph for top 20 Music NAMES\n",
    "import plotly.express as px\n",
    "def visualize_top20_MusicName(df_final):\n",
    "    #Unique values for Music Names\n",
    "    df_bar_music_name=unique_values(df_final,'Music Name')\n",
    "    #Skipped 1st music name since random orignal music is represented as 'orginal music'. \n",
    "    # Thus the category 'orginal music' represent multiple songs\n",
    "    fig = px.bar(df_bar_music_name[1:20], y='counts', x='unique_values',text='counts')\n",
    "    fig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\n",
    "    return fig\n",
    "\n",
    "fig=visualize_top20_MusicName(df_final)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bar graph for top trensding music id using plotly\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "def visualize_top20_MusicID(df_final):\n",
    "    # #Unique values for Music Ids\n",
    "    df_bar_music_id=unique_values(df_final,'Music Id')\n",
    "    index=list(range(10))\n",
    "    music_id = list(df_bar_music_id['unique_values'][0:10])\n",
    "    counts = list(df_bar_music_id['counts'][0:10])\n",
    "    Table=[]\n",
    "    Table.append(['Index','Music Id','Count'])\n",
    "    for  i in range(0,len(music_id)):\n",
    "        Table.append([i,music_id[i],counts[i]])\n",
    "\n",
    "    fig = ff.create_table(Table, height_constant=60)\n",
    "\n",
    "    Music_Bar = go.Bar(x=index, y=counts, xaxis='x2', yaxis='y2',\n",
    "                    marker=dict(color='#0099ff'),\n",
    "                    name='Count')\n",
    "\n",
    "    fig.add_traces(Music_Bar)\n",
    "\n",
    "    # initialize xaxis2 and yaxis2\n",
    "    fig['layout']['xaxis2'] = {}\n",
    "    fig['layout']['yaxis2'] = {}\n",
    "\n",
    "    # Edit layout for subplots\n",
    "    fig.layout.xaxis.update({'domain': [0, .5]})\n",
    "    fig.layout.xaxis2.update({'domain': [0.6, 1.]})\n",
    "\n",
    "    # The graph's yaxis MUST BE anchored to the graph's xaxis\n",
    "    fig.layout.yaxis2.update({'anchor': 'x2'})\n",
    "    fig.layout.yaxis2.update({'title': 'Count'})\n",
    "    fig.layout.xaxis2.update({'title': 'index'})\n",
    "\n",
    "    fig.layout.margin.update({'t':75, 'l':50})\n",
    "    fig.layout.update({'title': 'Trending Music on TikTok'})\n",
    "    return fig\n",
    "\n",
    "fig=visualize_top20_MusicID(df_final)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bar graph for top 10 challenge combinations\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "def visualize_top10_challenge_combination(df_final):\n",
    "    #Unique values for Challenge combination\n",
    "    df_bar_combination=unique_values(remove_zero_challenges(df_final),'challenge_list_Name')\n",
    "    df_bar_combination1=df_bar_combination[df_bar_combination['unique_values'].apply(lambda x: len(x)>1)].reset_index(drop=True)\n",
    "    index=list(range(10))\n",
    "    challenge_id = list(df_bar_combination1['unique_values'][0:10])\n",
    "    counts = list(df_bar_combination1['counts'][0:10])\n",
    "    Table=[]\n",
    "    Table.append(['Index','Challenges','Count'])\n",
    "    for  i in range(0,len(challenge_id)):\n",
    "        Table.append([i,challenge_id[i],counts[i]])\n",
    "\n",
    "    fig = ff.create_table(Table, height_constant=60)\n",
    "    fig.layout.width=1000\n",
    "    Challenge_Combination_Bar = go.Bar(x=index, y=counts, xaxis='x2', yaxis='y2',\n",
    "                    marker=dict(color='#0099ff'),\n",
    "                    name='Count')\n",
    "\n",
    "    fig.add_traces(Challenge_Combination_Bar)\n",
    "\n",
    "    # initialize xaxis2 and yaxis2\n",
    "    fig['layout']['xaxis2'] = {}\n",
    "    fig['layout']['yaxis2'] = {}\n",
    "\n",
    "    # Edit layout for subplots\n",
    "    fig.layout.xaxis.update({'domain': [0, .5]})\n",
    "    fig.layout.xaxis2.update({'domain': [0.6, 1.]})\n",
    "\n",
    "    # The graph's yaxis MUST BE anchored to the graph's xaxis\n",
    "    fig.layout.yaxis2.update({'anchor': 'x2'})\n",
    "    fig.layout.yaxis2.update({'title': 'Count'})\n",
    "    fig.layout.xaxis2.update({'title': 'index'})\n",
    "\n",
    "    fig.layout.margin.update({'t':75, 'l':50})\n",
    "    fig.layout.update({'title': 'Trending Challenge Combination on TikTok'})\n",
    "    return fig\n",
    "\n",
    "fig=visualize_top10_challenge_combination(df_final)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connected graph displaying Challenges associated with Music across dataset\n",
    "\n",
    "import d3fdgraph\n",
    "import pandas\n",
    "def visualize_hashtag_for_music(df_graph,musicid):\n",
    "    listauthor=df_graph.index[df_graph['Music ID'] == musicid].tolist()\n",
    "    cols = ['source','target','weight']\n",
    "    list_directed_graph=[]\n",
    "    #Create list having format Music Id : challenge1;  \n",
    "    for i in listauthor:\n",
    "        list_directed_graph.append([df_graph['Music ID'][i],df_graph['challenge_list_Name'][i],5])\n",
    "\n",
    "    df_directed_graph=pd.DataFrame(list_directed_graph,columns=cols)\n",
    "    d3fdgraph.plot_force_directed_graph(df_directed_graph, node_radius=15, link_distance=30, collision_scale=4)\n",
    "    \n",
    "visualize_hashtag_for_music(create_df_graph(remove_zero_challenges(df_final)),'6735137560026172166')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############## An alternate to website : Interactive plots (just an example)#########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from ipywidgets import widgets\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/yankev/testing/master/datasets/nycflights.csv')\n",
    "df = df.drop(df.columns[[0]], axis=1)\n",
    "df['carrier'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = widgets.IntSlider(\n",
    "    value=1.0,\n",
    "    min=1.0,\n",
    "    max=12.0,\n",
    "    step=1.0,\n",
    "    description='Month:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "use_date = widgets.Checkbox(\n",
    "    description='Date: ',\n",
    "    value=True,\n",
    ")\n",
    "\n",
    "container = widgets.HBox(children=[use_date, month])\n",
    "\n",
    "textbox = widgets.Dropdown(\n",
    "    description='Airline:   ',\n",
    "    value='DL',\n",
    "    options=df['carrier'].unique().tolist()\n",
    ")\n",
    "\n",
    "origin = widgets.Dropdown(\n",
    "    options=list(df['origin'].unique()),\n",
    "    value='LGA',\n",
    "    description='Origin Airport:',\n",
    ")\n",
    "\n",
    "\n",
    "# Assign an empty figure widget with two traces\n",
    "trace1 = go.Histogram(x=df['arr_delay'], opacity=0.75, name='Arrival Delays')\n",
    "trace2 = go.Histogram(x=df['dep_delay'], opacity=0.75, name='Departure Delays')\n",
    "g = go.FigureWidget(data=[trace1, trace2],\n",
    "                    layout=go.Layout(\n",
    "                        title=dict(\n",
    "                            text='NYC FlightDatabase'\n",
    "                        ),\n",
    "                        barmode='overlay'\n",
    "                    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    if origin.value in df['origin'].unique() and textbox.value in df['carrier'].unique():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def response(change):\n",
    "    if validate():\n",
    "        if use_date.value:\n",
    "            filter_list = [i and j and k for i, j, k in\n",
    "                           zip(df['month'] == month.value, df['carrier'] == textbox.value,\n",
    "                               df['origin'] == origin.value)]\n",
    "            temp_df = df[filter_list]\n",
    "\n",
    "        else:\n",
    "            filter_list = [i and j for i, j in\n",
    "                           zip(df['carrier'] == 'DL', df['origin'] == origin.value)]\n",
    "            temp_df = df[filter_list]\n",
    "        x1 = temp_df['arr_delay']\n",
    "        x2 = temp_df['dep_delay']\n",
    "        with g.batch_update():\n",
    "            g.data[0].x = x1\n",
    "            g.data[1].x = x2\n",
    "            g.layout.barmode = 'overlay'\n",
    "            g.layout.xaxis.title = 'Delay in Minutes'\n",
    "            g.layout.yaxis.title = 'Number of Delays'\n",
    "\n",
    "\n",
    "origin.observe(response, names=\"value\")\n",
    "textbox.observe(response, names=\"value\")\n",
    "month.observe(response, names=\"value\")\n",
    "use_date.observe(response, names=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container2 = widgets.HBox([origin, textbox])\n",
    "widgets.VBox([container,\n",
    "              container2,\n",
    "              g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
